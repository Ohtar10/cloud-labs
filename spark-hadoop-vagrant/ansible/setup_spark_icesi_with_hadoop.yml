---
- hosts: local
  gather_facts: False
  tasks:
    - name: Get Spark
      get_url: 
        url: https://www-us.apache.org/dist/spark/spark-2.4.3/spark-2.4.3-bin-hadoop2.7.tgz
        dest: resources/
        mode: 0776

- hosts: cluster
  gather_facts: True
  vars:
    var_software_path: "/home/{{ lookup('env','USER') }}/software"
    var_hadoop_home: "{{ var_software_path }}/hadoop"
    var_spark_home: "{{ var_software_path }}/spark"
  tasks:
    - name: Inflate Spark on remote hosts
      unarchive: 
        src: resources/spark-2.4.3-bin-hadoop2.7.tgz
        dest: "{{ var_software_path }}"
        owner: "{{ lookup('env', 'USER') }}"
        group: "{{ lookup('env', 'USER') }}"
    
    - name: Ensure symlink to spark
      file:
        src: "{{ var_software_path }}/spark-2.4.3-bin-hadoop2.7"
        dest: "{{ var_spark_home }}"
        state: link
        owner: "{{ lookup('env', 'USER') }}"
        group: "{{ lookup('env', 'USER') }}"
    
    - name: Ensure SPARK_HOME environment variable is set
      lineinfile:
        path: "/home/{{ lookup('env', 'USER') }}/.bashrc"
        create: yes
        state: present
        line: "export SPARK_HOME={{ var_spark_home }}"

    - name: Ensure HADOOP_CONF_DIR environment variable is set
      lineinfile:
        path: "{{ var_spark_home }}/conf/spark-env.sh"
        create: yes
        state: present
        line: "export HADOOP_CONF_DIR={{ var_hadoop_home }}/etc/hadoop"

    - name: Ensure YARN_CONF_DIR environment variable is set
      lineinfile:
        path: "{{ var_spark_home }}/conf/spark-env.sh"
        create: yes
        state: present
        line: "export YARN_CONF_DIR={{ var_hadoop_home }}/etc/hadoop"

    - name: Ensure SPARK_HOME is added to PATH
      lineinfile:
        path: "/home/{{ lookup('env', 'USER') }}/.bashrc"
        create: yes
        state: present
        line: "export PATH=$PATH:$SPARK_HOME/bin"
