---
- hosts: local
  gather_facts: False
  tasks:
    - name: Get Hadoop
      get_url:
        url: https://www-us.apache.org/dist/hadoop/common/hadoop-3.2.0/hadoop-3.2.0.tar.gz
        dest: resources/
        mode: 0776

# Since we are working in pseudo distributed mode we only need to target the first host alone
- hosts: cluster
  gather_facts: True
  vars:    
    var_software_path: "/home/{{ lookup('env','USER') }}/software"
    var_hadoop_home: "{{ var_software_path }}/hadoop"
    var_hadoop_dir: "/grid/lferro/dfs"
    # var_java_home: "/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.212.b04-0.el7_6.x86_64"
    var_java_home: /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.201.b09-2.el7_6.x86_64
    var_config_files: "resources/configs/pseudo-distributed/"
  tasks:
    
    - name: Ensure JAVA_HOME environment variable is setup
      lineinfile:
        path: /home/{{ lookup('env', 'USER') }}/.bashrc
        create: yes
        state: present
        line: "export JAVA_HOME={{ var_java_home }}"

    - name: Inflate Hadoop on {{ var_software_path }}
      unarchive:
        src: resources/hadoop-3.2.0.tar.gz
        dest: "{{ var_software_path }}"
        owner: "{{ lookup('env', 'USER') }}"
        group: "{{ lookup('env', 'USER') }}"

    - name: Ensure symlink to hadoop
      file: 
        src: "{{ var_software_path }}/hadoop-3.2.0"
        dest: "{{ var_hadoop_home }}"
        state: link
        owner: "{{ lookup('env', 'USER') }}"
        group: "{{ lookup('env', 'USER') }}"

    - name: Ensure HADOOP_HOME environment variable is setup
      lineinfile:
        path: /home/{{ lookup('env', 'USER') }}/.bashrc
        create: yes
        state: present
        line: "export HADOOP_HOME={{ var_hadoop_home }}"

    - name: Ensure HADOOP_HOME is added to PATH for hduser
      lineinfile:
        path: /home/{{ lookup('env', 'USER') }}/.bashrc
        create: yes
        state: present
        line: "export PATH=$PATH:$HADOOP_HOME/bin"

    # Configuration files on hadoop
    - name: Ensure JAVA_HOME variable on hadoop-env.sh is set correctly
      lineinfile:
        path: "{{ var_hadoop_home }}/etc/hadoop/hadoop-env.sh"
        regexp: '^export JAVA_HOME=${JAVA_HOME}'
        line: 'export JAVA_HOME={{ var_java_home }}'

    - name: Ensure HEAP_SIZE variable on hadoop-env.sh is set to 1024
      lineinfile:
        path: "{{ var_hadoop_home }}/etc/hadoop/hadoop-env.sh"
        regexp: '^#export HADOOP_HEAPSIZE='
        line: 'export HADOOP_HEAPSIZE=1024'

    - name: Copy Hadoop configuration files
      copy:
        src: "{{ var_config_files }}/{{ item }}"
        dest: "{{ var_hadoop_home }}/etc/hadoop"
        owner: "{{ lookup('env', 'USER') }}"
        group: "{{ lookup('env', 'USER') }}"
      with_items:
        - core-site.xml
        - hdfs-site.xml
        - mapred-site.xml
        - yarn-site.xml
        - workers

    - name: Ensure the workers file contains the right hostname
      lineinfile:
        path: "{{ var_hadoop_home }}/etc/hadoop/workers"
        regexp: "node1"
        line: "{{ ansible_hostname }}"
    
    - name: Ensure the NN hostname is the expected in core-site.xml
      lineinfile:
        path: "{{ var_hadoop_home }}/etc/hadoop/core-site.xml"
        regexp: "<value>hdfs://node1:8020</value>"
        line: "<value>hdfs://{{ ansible_hostname }}:8020</value>"

    - name: Set the name dir in hdfs-site.xml
      lineinfile:
        path: "{{ var_hadoop_home }}/etc/hadoop/hdfs-site.xml"
        regexp: "<value>/home/hduser/name</value>"
        line: "<value>{{ var_hadoop_dir }}/name</value>"

    - name: Set the data dir in hdfs-site.xml
      lineinfile:
        path: "{{ var_hadoop_home }}/etc/hadoop/hdfs-site.xml"
        regexp: "<value>/home/hduser/data</value>"
        line: "<value>{{ var_hadoop_dir }}/data</value>"

    # Final preparations to bring up the pseudo distributed mode
    - name: Format the namenode
      shell: bin/hdfs namenode -format
      args:
        chdir: "{{ var_hadoop_home }}"
        creates: "/tmp/hadoop-{{ lookup('env', 'USER') }}/dfs/name/current/fsimage_0000000000000000000"

    # Ensure non strict host key checking as might interfere with automated startup
    - name: Ensure no Strict Host Key Checking
      copy:
        src: resources/configs/ssh_config
        dest: /home/{{ lookup('env', 'USER') }}/.ssh/config
        mode: 600
        owner: "{{ lookup('env', 'USER') }}"
        group: "{{ lookup('env', 'USER') }}"

    # In case of failing to connect to namenode because it is not started and need to be
    # Restarted again, command sbin/hadoop-daemon.sh start namenode needs to be executed
    - name: Ensure HDFS daemons are started
      shell: sbin/start-dfs.sh
      args:
        chdir: "{{ var_hadoop_home }}"
        creates: /tmp/hadoop-hduser/hadoop-hduser-namenode.pid

    - name: Ensure YARN daemons are started
      shell: sbin/start-yarn.sh
      args:
        chdir: "{{ var_hadoop_home }}"
        creates: /tmp/hadoop-hduser/yarn-hduser-nodemanager.pid

