---
- hosts: local
  gather_facts: False
  tasks:
    - name: Get Hadoop
      get_url:
        url: https://www-us.apache.org/dist/hadoop/common/hadoop-3.2.0/hadoop-3.2.0.tar.gz
        dest: resources/
        mode: 0776

- hosts: cluster
  gather_facts: False
  become: True
  vars:
    # Generate passworkd hash with: ansible all -m debug -a "msg={{ 'hduser' | password_hash('sha512', 'hduser')}}"
    var_hduser_psw: $6$hduser$sn14ciKozJ/aOrye3jpD1uQoF.OXh/2stFyaVvx/GkDH76tEg3h013W6.nKyCwVggG3/M3NXcJpQkODUlnm7B.
  tasks:
    - name: Ensure Java 1.8 Devel and tools are installed
      yum: 
        name: ['iptables-services', 'nano', 'net-tools', 'telnet', 'java-1.8.0-openjdk-devel'] 
        state: 'present' 
        update_cache: 'yes'

    # Bring down the firewall so don't interfere with communication between nodes
    - name: Bring down the firewall
      service: name=iptables state=stopped enabled=no

    - name: Ensure hadoop group exists
      group: name=hadoop state=present

    - name: Ensure hduser exists and is added to the hadoop group
      user: 
        name: hduser
        groups: hadoop
        state: present
        password: "{{ var_hduser_psw }}"
        generate_ssh_key: yes
        ssh_key_bits: 2048
        ssh_key_file: .ssh/id_rsa

    # Ensure non strict host key checking as might interfere with automated startup
    - name: Ensure no Strict Host Key Checking
      copy:
        src: resources/configs/ssh_config
        dest: /home/hduser/.ssh/config
        owner: hduser
        group: hduser

    - name: Ensure hduser has sudo with passwordless privileges
      lineinfile: 
        path: /etc/sudoers.d/hduser
        create: yes
        state: present
        line: "%hduser ALL=(ALL) NOPASSWD: ALL"

    - name: Get public key from hosts
      fetch: 
        src: "/home/hduser/.ssh/id_rsa.pub"
        dest: "/keys"

    - name: Distribute public keys are distributed among cluster members
      authorized_key:
        user: hduser
        state: present
        key: "{{ item }}"
      #with_items: "{{ '/keys/*/home/hduser/.ssh/id_rsa.pub' | fileglob }}"
      with_file:
        - /keys/node1/home/hduser/.ssh/id_rsa.pub
        - /keys/node2/home/hduser/.ssh/id_rsa.pub
        - /keys/node3/home/hduser/.ssh/id_rsa.pub
        - /keys/node4/home/hduser/.ssh/id_rsa.pub
        - /keys/node5/home/hduser/.ssh/id_rsa.pub
    
    - name: Ensure JAVA_HOME environment variable is setup
      lineinfile:
        path: /home/hduser/.bashrc
        create: yes
        state: present
        line: "export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk"

    - name: Inflate Hadoop on /usr/local
      unarchive:
        src: resources/hadoop-3.2.0.tar.gz
        dest: /usr/local/
        owner: "hduser"
        group: "hduser"

    - name: Ensure symlink to hadoop
      file: 
        src: /usr/local/hadoop-3.2.0
        dest: /usr/local/hadoop
        state: link
        owner: "hduser"
        group: "hduser"

    - name: Copy Hadoop configuration files
      copy:
        src: resources/configs/fully-distributed/{{ item }}
        dest: /usr/local/hadoop/etc/hadoop
        owner: "hduser"
        group: "hduser"
      with_items:
        - core-site.xml
        - hdfs-site.xml
        - mapred-site.xml
        - yarn-site.xml
        - workers

    - name: Ensure HADOOP_HOME environment variable is setup
      lineinfile:
        path: /home/hduser/.bashrc
        create: yes
        state: present
        line: "export HADOOP_HOME=/usr/local/hadoop"

    - name: Ensure JAVA_HOME and HADOOP_HOME is added to PATH for hduser
      lineinfile:
        path: /home/hduser/.bashrc
        create: yes
        state: present
        line: "export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin"

    # Clear automatically the logs when the machine is started up
    - name: Ensure tmp clean after init scripts
      lineinfile:
        path: /etc/rc.d/rc.local
        create: yes
        state: present
        line: "/bin/rm -rf /tmp/*"

    # Configuration files on hadoop
    - name: Ensure JAVA_HOME variable on *-env.sh is set correctly
      lineinfile:
        path: /usr/local/hadoop/etc/hadoop/hadoop-env.sh
        regexp: '^[#\s]{0,2}export JAVA_HOME=.+'
        line: 'export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk'
      with_items:
        - hadoop-env.sh
        - mapred-env.sh
        - yarn-env.sh

    - name: Ensure HEAP_SIZE variable on hadoop-env.sh is set to 200
      lineinfile:
        path: /usr/local/hadoop/etc/hadoop/hadoop-env.sh
        regexp: '^#export HADOOP_HEAPSIZE='
        line: 'export HADOOP_HEAPSIZE=200'


- hosts: namenode
  gather_facts: False
  become: True
  tasks:
    # This is important as avoids running the namenode using 127.0.0.1 which will prevent slaves nodes to connect
    - name: Ensure /etc/hosts maps for node1 are not pointing to 127.0.0.1 only
      lineinfile:
        path: /etc/hosts
        regexp: '^127.0.0.1	node1	node1'
        line: '#127.0.0.1	node1	node1'
    # Final preparations to bring up the pseudo distributed mode
    - name: Format the namenode
      shell: bin/hdfs namenode -format playground-cluster
      args:
        chdir: /usr/local/hadoop
        creates: /home/hduser/namenode/current/fsimage_0000000000000000000
      become: yes
      become_user: hduser

    # In case of failing to connect to namenode because it is not started and need to be
    # Restarted again, command sbin/hadoop-daemon.sh start namenode needs to be executed
    - name: Ensure Namenode is started
      shell: sbin/start-dfs.sh
      args:
        chdir: /usr/local/hadoop
        creates: /tmp/hadoop-hduser/hadoop-hduser-namenode.pid
      become: yes
      become_user: hduser

- hosts: yarn
  gather_facts: False
  become: True
  tasks:
    - name: Ensure YARN daemons are started
      shell: sbin/start-yarn.sh
      args:
        chdir: /usr/local/hadoop
        creates: /tmp/hadoop-hduser/yarn-hduser-nodemanager.pid
      become: yes
      become_user: hduser

- hosts: mrjobhistory
  gather_facts: False
  become: True
  tasks:
    - name: Ensure Job History Server daemons are started
      shell: sbin/mr-jobhistory-daemon.sh --config /usr/local/hadoop/etc/hadoop/ start historyserver
      args:
        chdir: /usr/local/hadoop
        creates: /tmp/hadoop-hduser/yarn-hduser-nodemanager.pid
      become: yes
      become_user: hduser

