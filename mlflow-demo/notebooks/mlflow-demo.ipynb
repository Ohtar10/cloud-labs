{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('mlflow-demo': conda)",
   "display_name": "Python 3.8.5 64-bit ('mlflow-demo': conda)",
   "metadata": {
    "interpreter": {
     "hash": "daa9790791a41f05c65445cd3bc9abfbbd57bebd0b1a537ee075fbf5099551c0"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# MLflow Demo\n",
    "\n",
    "## Resources:\n",
    "* https://mlflow.org/docs/latest/quickstart.html\n",
    "\n",
    "This notebook summarizes basic use cases for MLflow that helps visualizing and understanding the benefits of it.\n",
    "\n",
    "This notebook is purely bash commands to interact with an mlflow runtime in docker. This demo includes playing around with the mlflow demos in which we can have scikit-learn and pytorch models, as well as environment configurations in both conda and docker.\n",
    "\n",
    "## MLflow Overview\n",
    "One way to summarize mlflow's value proposal is as follows:\n",
    "* Enables and facilitates the environment configuration needed to run experiments (via conda and docker)\n",
    "* Enables and facilitates experiment tracking.\n",
    "* Enables and facilitates model storage and serving for quick AdHoc experiments.\n",
    "* It does the above with few additional stuff in the project, it integrates with popular ML frameworks and even other monitoring tools like tensorboard.\n",
    "\n",
    "## MLflow Runtime\n",
    "MLflow uses a tracking server to do just that. Tracking experiments, storing models, some basic reporting and managing the runtime environment for each experiment. The tracking server can be both local or remote. The local tracking server is best for local experiments, e.g., during development etc. And the remote server is more suited to heavy training. It is important to clarify that this server is only for tracking and storing artifacts. It is not a runtime for experiments. Each experiment can run anywhere, the experiment runtime just need to have access to the tracking server to report progress.\n",
    "\n",
    "In local runtime, mlflow can be used to recreate experiments from scratch without needing to manually configure anything.\n",
    "\n",
    "### Installation\n",
    "Within a python or conda environment, install mlflow with `pip install mlflow`. The CLI tool gets installed and you can start working with mlflow. The github repo has a lot of examples: https://github.com/mlflow/mlflow.\n",
    "\n",
    "### Running a simple experiment\n",
    "For illustration purposes, let's write a simple program to log dummy metrics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import random, randint\n",
    "from mlflow import log_metric, log_param, log_artifacts\n",
    "\n",
    "# log a parameter\n",
    "log_param(\"param1\", randint(0, 100))\n",
    "\n",
    "# log a metric\n",
    "log_metric(\"foo\", random())\n",
    "log_metric(\"foo\", random() + 1)\n",
    "log_metric(\"foo\", random() + 2)\n",
    "\n",
    "# log an artifact\n",
    "outputs = \"/tmp/mlflow-demo/outputs\"\n",
    "if not os.path.exists(outputs):\n",
    "    os.makedirs(outputs)\n",
    "with open(os.path.join(outputs, \"test.txt\"), \"w\") as f:\n",
    "    f.write(\"hello world!\")\n",
    "log_artifacts(outputs)"
   ]
  },
  {
   "source": [
    "The above code does three things:\n",
    "\n",
    "1. It logs a parameter, for instance a model hyperparameter, like the learning rate, epochs, etc.\n",
    "2. It logs metrics, during training, you can log the metrics progess which changes over time, like accuracy, loss, etc.\n",
    "3. It logs artifacts to recreate the model, like the model + weights, this gets persisted and sent to the server for later usage.\n",
    "\n",
    "The above code also produces a folder called 'mlruns' in your working directory which is to track everything you decide to log."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[01;34m./mlruns/\u001b[00m\n└── \u001b[01;34m0\u001b[00m\n    ├── \u001b[01;34m0732020976b14911a7eada8185d82a87\u001b[00m\n    │   ├── \u001b[01;34martifacts\u001b[00m\n    │   │   └── test.txt\n    │   ├── meta.yaml\n    │   ├── \u001b[01;34mmetrics\u001b[00m\n    │   │   └── foo\n    │   ├── \u001b[01;34mparams\u001b[00m\n    │   │   └── param1\n    │   └── \u001b[01;34mtags\u001b[00m\n    │       ├── mlflow.source.name\n    │       ├── mlflow.source.type\n    │       └── mlflow.user\n    └── meta.yaml\n\n6 directories, 8 files\n"
     ]
    }
   ],
   "source": [
    "!tree ./mlruns/"
   ]
  },
  {
   "source": [
    "We can save the exact same code as a python script and execute it as a standalone program"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python mlflow_tracking.py"
   ]
  },
  {
   "source": [
    "Everything runs locally. If we want to visualize the results, we can start the ui via `mlflow ui` which runs a server listening on `http://localhost:5000` by default. This command should be executed at `mlruns` parent folder, so the ui can read it and display the experiments as shown in the picture. There we can observe the experiments we just run, as well as the metrics. If we click in the experiments, we can observe the artifact we saved as well.\n",
    "\n",
    "![mlflow-ui](images/mlflow-ui.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## MLflow projects\n",
    "An MLflow project is like a package containing all the necessary artifacts to run an experiment, including the runtime environment definition (as a conda enviroment or a Dockerfile) and an additional file that tells MLflow some attributes about the project endpoints, input parameters, etc. This is necessary to enable running experiments against an external tracking server.\n",
    "\n",
    "We can run experiments directly from a github repository or a local folder. In local mode the results are again stored in `mlruns` and can be viewed with the ui.\n",
    "\n",
    "For example, let's run one of the mlflow examples at https://github.com/mlflow/mlflow-example.git, this is a simple scikit-learn model to predict wine quality. It only consists in the project definition file, a conda environment file, the data set in csv format and the python scripts that trains the model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2020/10/14 17:50:00 INFO mlflow.projects.utils: === Fetching project from https://github.com/mlflow/mlflow-example.git into /tmp/tmpborqt582 ===\n",
      "2020/10/14 17:50:04 INFO mlflow.utils.conda: === Creating conda environment mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b ===\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.8.4\n",
      "  latest version: 4.8.5\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "pip-20.2.3           | 1.7 MB    | ##################################### | 100% \n",
      "setuptools-50.3.0    | 710 KB    | ##################################### | 100% \n",
      "pandas-1.1.3         | 8.1 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Installing pip dependencies: / Ran pip subprocess with arguments:\n",
      "['/home/ohtar10/miniconda3/envs/mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b/bin/python', '-m', 'pip', 'install', '-U', '-r', '/tmp/tmpborqt582/condaenv.2d7sxlw0.requirements.txt']\n",
      "Pip subprocess output:\n",
      "Collecting mlflow\n",
      "  Using cached mlflow-1.11.0-py3-none-any.whl (13.9 MB)\n",
      "Collecting docker>=4.0.0\n",
      "  Using cached docker-4.3.1-py2.py3-none-any.whl (145 kB)\n",
      "Collecting requests>=2.17.3\n",
      "  Using cached requests-2.24.0-py2.py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied, skipping upgrade: pandas in /home/ohtar10/miniconda3/envs/mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b/lib/python3.7/site-packages (from mlflow->-r /tmp/tmpborqt582/condaenv.2d7sxlw0.requirements.txt (line 1)) (1.1.3)\n",
      "Collecting sqlparse\n",
      "  Using cached sqlparse-0.4.1-py3-none-any.whl (42 kB)\n",
      "Collecting Flask\n",
      "  Using cached Flask-1.1.2-py2.py3-none-any.whl (94 kB)\n",
      "Processing /home/ohtar10/.cache/pip/wheels/69/38/7a/072b5863ca334d012821a287fd1d066cea33abdcda3ef2f878/querystring_parser-1.2.4-py3-none-any.whl\n",
      "Collecting cloudpickle\n",
      "  Using cached cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
      "Collecting click>=7.0\n",
      "  Using cached click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting entrypoints\n",
      "  Using cached entrypoints-0.3-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil in /home/ohtar10/miniconda3/envs/mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b/lib/python3.7/site-packages (from mlflow->-r /tmp/tmpborqt582/condaenv.2d7sxlw0.requirements.txt (line 1)) (2.8.1)\n",
      "Processing /home/ohtar10/.cache/pip/wheels/5e/03/1e/e1e954795d6f35dfc7b637fe2277bff021303bd9570ecea653/PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl\n",
      "Collecting gorilla\n",
      "  Using cached gorilla-0.3.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting gunicorn; platform_system != \"Windows\"\n",
      "  Using cached gunicorn-20.0.4-py2.py3-none-any.whl (77 kB)\n",
      "Collecting protobuf>=3.6.0\n",
      "  Using cached protobuf-3.13.0-cp37-cp37m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /home/ohtar10/miniconda3/envs/mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b/lib/python3.7/site-packages (from mlflow->-r /tmp/tmpborqt582/condaenv.2d7sxlw0.requirements.txt (line 1)) (1.15.4)\n",
      "Collecting prometheus-flask-exporter\n",
      "  Using cached prometheus_flask_exporter-0.18.1.tar.gz (21 kB)\n",
      "Collecting azure-storage-blob>=12.0\n",
      "  Using cached azure_storage_blob-12.5.0-py2.py3-none-any.whl (326 kB)\n",
      "Collecting databricks-cli>=0.8.7\n",
      "  Using cached databricks-cli-0.12.2.tar.gz (55 kB)\n",
      "Processing /home/ohtar10/.cache/pip/wheels/be/5d/0a/9e13f53f4f5dfb67cd8d245bb7cdffe12f135846f491a283e3/alembic-1.4.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /home/ohtar10/miniconda3/envs/mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b/lib/python3.7/site-packages (from mlflow->-r /tmp/tmpborqt582/condaenv.2d7sxlw0.requirements.txt (line 1)) (1.15.0)\n",
      "Processing /home/ohtar10/.cache/pip/wheels/b9/ba/77/163f10f14bd489351530603e750c195b0ceceed2f3be2b32f1/SQLAlchemy-1.3.13-cp37-cp37m-linux_x86_64.whl\n",
      "Collecting gitpython>=2.1.0\n",
      "  Using cached GitPython-3.1.9-py3-none-any.whl (159 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Using cached websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\n",
      "Collecting chardet<4,>=3.0.2\n",
      "  Using cached chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Using cached idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
      "  Using cached urllib3-1.25.10-py2.py3-none-any.whl (127 kB)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/ohtar10/miniconda3/envs/mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b/lib/python3.7/site-packages (from requests>=2.17.3->mlflow->-r /tmp/tmpborqt582/condaenv.2d7sxlw0.requirements.txt (line 1)) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /home/ohtar10/miniconda3/envs/mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b/lib/python3.7/site-packages (from pandas->mlflow->-r /tmp/tmpborqt582/condaenv.2d7sxlw0.requirements.txt (line 1)) (2020.1)\n",
      "Collecting Jinja2>=2.10.1\n",
      "  Using cached Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Using cached itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting Werkzeug>=0.15\n",
      "  Using cached Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=3.0 in /home/ohtar10/miniconda3/envs/mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b/lib/python3.7/site-packages (from gunicorn; platform_system != \"Windows\"->mlflow->-r /tmp/tmpborqt582/condaenv.2d7sxlw0.requirements.txt (line 1)) (50.3.0.post20201006)\n",
      "Collecting prometheus_client\n",
      "  Using cached prometheus_client-0.8.0-py2.py3-none-any.whl (53 kB)\n",
      "Collecting msrest>=0.6.10\n",
      "  Using cached msrest-0.6.19-py2.py3-none-any.whl (84 kB)\n",
      "Collecting azure-core<2.0.0,>=1.6.0\n",
      "  Downloading azure_core-1.8.2-py2.py3-none-any.whl (122 kB)\n",
      "Collecting cryptography>=2.1.4\n",
      "  Using cached cryptography-3.1.1-cp35-abi3-manylinux2010_x86_64.whl (2.6 MB)\n",
      "Collecting tabulate>=0.7.7\n",
      "  Using cached tabulate-0.8.7-py3-none-any.whl (24 kB)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Using cached tenacity-6.2.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting python-editor>=0.3\n",
      "  Using cached python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
      "Collecting Mako\n",
      "  Using cached Mako-1.1.3-py2.py3-none-any.whl (75 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.5-py3-none-any.whl (63 kB)\n",
      "Collecting MarkupSafe>=0.23\n",
      "  Using cached MarkupSafe-1.1.1-cp37-cp37m-manylinux1_x86_64.whl (27 kB)\n",
      "Collecting isodate>=0.6.0\n",
      "  Using cached isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting cffi!=1.11.3,>=1.8\n",
      "  Using cached cffi-1.14.3-cp37-cp37m-manylinux1_x86_64.whl (401 kB)\n",
      "Collecting smmap<4,>=3.0.1\n",
      "  Using cached smmap-3.0.4-py2.py3-none-any.whl (25 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting pycparser\n",
      "  Using cached pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Building wheels for collected packages: prometheus-flask-exporter, databricks-cli\n",
      "  Building wheel for prometheus-flask-exporter (setup.py): started\n",
      "  Building wheel for prometheus-flask-exporter (setup.py): finished with status 'done'\n",
      "  Created wheel for prometheus-flask-exporter: filename=prometheus_flask_exporter-0.18.1-py3-none-any.whl size=17157 sha256=1b6549f1a7636ac66b61743c613c0be9bc07579f14f0ac49b7ae3c66060a2df5\n",
      "  Stored in directory: /home/ohtar10/.cache/pip/wheels/c4/b6/b5/e76659f3b2a3a226565e27f0a7eb7a3ac93c3f4d68acfbe617\n",
      "  Building wheel for databricks-cli (setup.py): started\n",
      "  Building wheel for databricks-cli (setup.py): finished with status 'done'\n",
      "  Created wheel for databricks-cli: filename=databricks_cli-0.12.2-py3-none-any.whl size=101164 sha256=158f1b3e630391856ca36cee66eb3426ecdfab14a03d82e63574430a272b6d7c\n",
      "  Stored in directory: /home/ohtar10/.cache/pip/wheels/9e/bb/9d/78e02afa234019a22759d08d285bae87a88fa881f5db58db25\n",
      "Successfully built prometheus-flask-exporter databricks-cli\n",
      "Installing collected packages: websocket-client, chardet, idna, urllib3, requests, docker, sqlparse, MarkupSafe, Jinja2, click, itsdangerous, Werkzeug, Flask, querystring-parser, cloudpickle, entrypoints, pyyaml, gorilla, gunicorn, protobuf, prometheus-client, prometheus-flask-exporter, isodate, oauthlib, requests-oauthlib, msrest, azure-core, pycparser, cffi, cryptography, azure-storage-blob, tabulate, tenacity, databricks-cli, python-editor, sqlalchemy, Mako, alembic, smmap, gitdb, gitpython, mlflow\n",
      "Successfully installed Flask-1.1.2 Jinja2-2.11.2 Mako-1.1.3 MarkupSafe-1.1.1 Werkzeug-1.0.1 alembic-1.4.1 azure-core-1.8.2 azure-storage-blob-12.5.0 cffi-1.14.3 chardet-3.0.4 click-7.1.2 cloudpickle-1.6.0 cryptography-3.1.1 databricks-cli-0.12.2 docker-4.3.1 entrypoints-0.3 gitdb-4.0.5 gitpython-3.1.9 gorilla-0.3.0 gunicorn-20.0.4 idna-2.10 isodate-0.6.0 itsdangerous-1.1.0 mlflow-1.11.0 msrest-0.6.19 oauthlib-3.1.0 prometheus-client-0.8.0 prometheus-flask-exporter-0.18.1 protobuf-3.13.0 pycparser-2.20 python-editor-1.0.4 pyyaml-5.3.1 querystring-parser-1.2.4 requests-2.24.0 requests-oauthlib-1.3.0 smmap-3.0.4 sqlalchemy-1.3.13 sqlparse-0.4.1 tabulate-0.8.7 tenacity-6.2.0 urllib3-1.25.10 websocket-client-0.57.0\n",
      "\n",
      "done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "2020/10/14 17:50:38 INFO mlflow.projects.utils: === Created directory /tmp/tmp6qx9gdws for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2020/10/14 17:50:38 INFO mlflow.projects.backend.local: === Running command 'source /home/ohtar10/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b 1>&2 && python train.py 5.0 0.1' in run with ID 'fdfc7640bc50423db89a666bf72e7b8d' === \n",
      "/home/ohtar10/miniconda3/envs/mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b/lib/python3.7/site-packages/sklearn/utils/__init__.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Sequence\n",
      "/home/ohtar10/miniconda3/envs/mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b/lib/python3.7/site-packages/sklearn/model_selection/_split.py:18: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Iterable\n",
      "/home/ohtar10/miniconda3/envs/mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b/lib/python3.7/site-packages/sklearn/model_selection/_search.py:16: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Mapping, namedtuple, defaultdict, Sequence\n",
      "Elasticnet model (alpha=5.000000, l1_ratio=0.100000):\n",
      "  RMSE: 0.8594260117338262\n",
      "  MAE: 0.6480675144220314\n",
      "  R2: 0.046025292604596424\n",
      "2020/10/14 17:50:39 INFO mlflow.projects: === Run (ID 'fdfc7640bc50423db89a666bf72e7b8d') succeeded ===\n"
     ]
    }
   ],
   "source": [
    "!mlflow run https://github.com/mlflow/mlflow-example.git -P alpha=5.0"
   ]
  },
  {
   "source": [
    "The first time we run the project via mlflow, it will automatically fetch all the files from the repository, and use the conda environment file to create the local conda environment to run the experiment. Then, mlflow runs the experiment as it was defined and will log the defined parameters, metrics and artifacts. If we explore the content of this project, the vast majority of it is related to scikit-learn and the model itself, and very few pieces are related to mlflow.\n",
    "\n",
    "The Project file is another yaml file that describes the project metadata, including the running environment specs and the entry points:\n",
    "\n",
    "```yaml\n",
    "name: tutorial\n",
    "\n",
    "conda_env: conda.yaml\n",
    "\n",
    "entry_points:\n",
    "  main:\n",
    "    parameters:\n",
    "      alpha: float\n",
    "      l1_ratio: {type: float, default: 0.1}\n",
    "    command: \"python train.py {alpha} {l1_ratio}\"\n",
    "```\n",
    "\n",
    "Through `conda_env` we tell mlflow which conda environment file we need to use to create the appropriate runtime environment before running the model. If the project is run again, the preexisting conda environment will be reused."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Serving models\n",
    "Now let's suppose after training the model we want to publish it for AdHoc testing. We can create endpoints from the executed experiments and make http requests to them.\n",
    "\n",
    "First, we need to execute an experiment:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score: 0.6666666666666666\n",
      "Model saved in run 263aa26bfccd434b818c18938591ceeb\n"
     ]
    }
   ],
   "source": [
    "!python ~/git/mlflow/examples/sklearn_logistic_regression/train.py"
   ]
  },
  {
   "source": [
    "Now, we can create an endpoint to the model with:\n",
    "```\n",
    "mlflow models serve -m ./notebooks/mlruns/0/263aa26bfccd434b818c18938591ceeb/artifacts/model -p 1234\n",
    "```\n",
    "\n",
    "Notice that in local mode we specify the path to the actual experiment using the run id we obtained above. We can also specify a custom port to expose. Finally, if there is no conda environment created for this service, mlflow will automatically create it for you, then serve the model which can be consumed via `curl`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1, 0]"
     ]
    }
   ],
   "source": [
    "!curl -d '{\"columns\":[\"x\"], \"data\":[[1], [-1]]}' -H 'Content-Type: application/json; format=pandas-split' -X POST http://localhost:1234/invocations"
   ]
  },
  {
   "source": [
    "### Working with docker environments\n",
    "So far, I have demonstrated the usage of mlflow projects to recreate the runtime environment via conda for both training and serving. However, we can also use docker instead. We just need to create the Dockerfile and image and specify it in the mlflow project instead of a conda environment. The runtime will create a container using that image and run the experiment. The rest of the process is exactly the same.\n",
    "\n",
    "#### Dockerfile example\n",
    "We can have anything we want in the docker file. For instance, this is a simple docker image based on miniconda and installing some packages.\n",
    "\n",
    "```\n",
    "FROM continuumio/miniconda:4.5.4\n",
    "\n",
    "RUN pip install mlflow>=1.0 \\\n",
    "    && pip install azure-storage-blob==12.3.0 \\\n",
    "    && pip install numpy==1.14.3 \\\n",
    "    && pip install scipy \\\n",
    "    && pip install pandas==0.22.0 \\\n",
    "    && pip install scikit-learn==0.19.1 \\\n",
    "    && pip install cloudpickle\n",
    "```\n",
    "\n",
    "We should build this image and put it in some docker registry as the image identifier is what we need to specify in the mlflow project."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Step 1/2 : FROM continuumio/miniconda:4.5.4\n",
      "4.5.4: Pulling from continuumio/miniconda\n",
      "\n",
      "\u001b[1B\n",
      "\u001b[1B\n",
      "\u001b[1B\n",
      "\u001b[1BDigest: sha256:19d3eedab8b6301a0e1819476cfc50d53399881612183cf65208d7d43db99cd9\n",
      "Status: Downloaded newer image for continuumio/miniconda:4.5.4\n",
      " ---> 16e4fbac86ce\n",
      "Step 2/2 : RUN pip install mlflow>=1.0     && pip install azure-storage-blob==12.3.0     && pip install numpy==1.14.3     && pip install scipy     && pip install pandas==0.22.0     && pip install scikit-learn==0.19.1     && pip install cloudpickle\n",
      " ---> Running in b541d45bb67c\n",
      "\u001b[91mYou are using pip version 10.0.1, however version 20.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "\u001b[0mCollecting azure-storage-blob==12.3.0\n",
      "  Downloading https://files.pythonhosted.org/packages/ff/76/5ed49519f30636beba06b4fab41e086abc9fa75ee79770e942e14c92136a/azure_storage_blob-12.3.0-py2.py3-none-any.whl (279kB)\n",
      "Collecting azure-core<2.0.0,>=1.2.2 (from azure-storage-blob==12.3.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/4c/fa/46974f4a7ad78b27e3eda8a573cc0c2508849f0d7d360b61c07cc5b46014/azure_core-1.8.2-py2.py3-none-any.whl (122kB)\n",
      "Requirement already satisfied: enum34>=1.0.4; python_version < \"3.4\" in /opt/conda/lib/python2.7/site-packages (from azure-storage-blob==12.3.0) (1.1.6)\n",
      "Collecting msrest>=0.6.10 (from azure-storage-blob==12.3.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/fa/f5/9e315fe8cb985b0ce052b34bcb767883dc739f46fadb62f05a7e6d6eedbe/msrest-0.6.19-py2.py3-none-any.whl (84kB)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in /opt/conda/lib/python2.7/site-packages (from azure-storage-blob==12.3.0) (2.2.2)\n",
      "Collecting azure-storage-nspkg<4.0.0,>=3.0.0; python_version < \"3.0\" (from azure-storage-blob==12.3.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/ba/f6/054ace7b01c6c21b3b95a83c3997f7d6539d939a2c08c4f27f779128a030/azure_storage_nspkg-3.1.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: futures; python_version < \"3.0\" in /opt/conda/lib/python2.7/site-packages (from azure-storage-blob==12.3.0) (3.2.0)\n",
      "Requirement already satisfied: typing; python_version < \"3.5\" in /opt/conda/lib/python2.7/site-packages (from azure-storage-blob==12.3.0) (3.7.4.3)\n",
      "Requirement already satisfied: six>=1.6 in /opt/conda/lib/python2.7/site-packages (from azure-core<2.0.0,>=1.2.2->azure-storage-blob==12.3.0) (1.11.0)\n",
      "Requirement already satisfied: requests>=2.18.4 in /opt/conda/lib/python2.7/site-packages (from azure-core<2.0.0,>=1.2.2->azure-storage-blob==12.3.0) (2.18.4)\n",
      "Collecting azure-nspkg; python_version < \"3.0\" (from azure-core<2.0.0,>=1.2.2->azure-storage-blob==12.3.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/c2/95/af354f2f415d250dafe26a5d94230558aa8cf733a9dcbf0d26cd61f5a9b8/azure_nspkg-3.0.2-py2-none-any.whl\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python2.7/site-packages (from msrest>=0.6.10->azure-storage-blob==12.3.0) (2018.4.16)\n",
      "Collecting requests-oauthlib>=0.5.0 (from msrest>=0.6.10->azure-storage-blob==12.3.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Collecting isodate>=0.6.0 (from msrest>=0.6.10->azure-storage-blob==12.3.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
      "Requirement already satisfied: idna>=2.1 in /opt/conda/lib/python2.7/site-packages (from cryptography>=2.1.4->azure-storage-blob==12.3.0) (2.6)\n",
      "Requirement already satisfied: asn1crypto>=0.21.0 in /opt/conda/lib/python2.7/site-packages (from cryptography>=2.1.4->azure-storage-blob==12.3.0) (0.24.0)\n",
      "Requirement already satisfied: cffi>=1.7 in /opt/conda/lib/python2.7/site-packages (from cryptography>=2.1.4->azure-storage-blob==12.3.0) (1.11.5)\n",
      "Requirement already satisfied: ipaddress in /opt/conda/lib/python2.7/site-packages (from cryptography>=2.1.4->azure-storage-blob==12.3.0) (1.0.22)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python2.7/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.2.2->azure-storage-blob==12.3.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /opt/conda/lib/python2.7/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.2.2->azure-storage-blob==12.3.0) (1.22)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.5.0->msrest>=0.6.10->azure-storage-blob==12.3.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python2.7/site-packages (from cffi>=1.7->cryptography>=2.1.4->azure-storage-blob==12.3.0) (2.18)\n",
      "Installing collected packages: azure-nspkg, azure-core, oauthlib, requests-oauthlib, isodate, msrest, azure-storage-nspkg, azure-storage-blob\n",
      "Successfully installed azure-core-1.8.2 azure-nspkg-3.0.2 azure-storage-blob-12.3.0 azure-storage-nspkg-3.1.0 isodate-0.6.0 msrest-0.6.19 oauthlib-3.1.0 requests-oauthlib-1.3.0\n",
      "\u001b[91mYou are using pip version 10.0.1, however version 20.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "\u001b[0mCollecting numpy==1.14.3\n",
      "  Downloading https://files.pythonhosted.org/packages/c0/e7/08f059a00367fd613e4f2875a16c70b6237268a1d6d166c6d36acada8301/numpy-1.14.3-cp27-cp27mu-manylinux1_x86_64.whl (12.1MB)\n",
      "Installing collected packages: numpy\n",
      "  Found existing installation: numpy 1.16.6\n",
      "    Uninstalling numpy-1.16.6:\n",
      "      Successfully uninstalled numpy-1.16.6\n",
      "Successfully installed numpy-1.14.3\n",
      "\u001b[91mYou are using pip version 10.0.1, however version 20.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "\u001b[0mCollecting scipy\n",
      "  Downloading https://files.pythonhosted.org/packages/24/40/11b12af7f322c1e20446c037c47344d89bab4922b8859419d82cf56d796d/scipy-1.2.3-cp27-cp27mu-manylinux1_x86_64.whl (24.8MB)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /opt/conda/lib/python2.7/site-packages (from scipy) (1.14.3)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.2.3\n",
      "\u001b[91mYou are using pip version 10.0.1, however version 20.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "\u001b[0mCollecting pandas==0.22.0\n",
      "  Downloading https://files.pythonhosted.org/packages/6b/b5/76538d8a202f8c368d30c18892d33664d1a3b2c078af8513ee5b5d172629/pandas-0.22.0-cp27-cp27mu-manylinux1_x86_64.whl (24.3MB)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python2.7/site-packages (from pandas==0.22.0) (2020.1)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /opt/conda/lib/python2.7/site-packages (from pandas==0.22.0) (1.14.3)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python2.7/site-packages (from pandas==0.22.0) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python2.7/site-packages (from python-dateutil->pandas==0.22.0) (1.11.0)\n",
      "Installing collected packages: pandas\n",
      "  Found existing installation: pandas 0.24.2\n",
      "    Uninstalling pandas-0.24.2:\n",
      "      Successfully uninstalled pandas-0.24.2\n",
      "Successfully installed pandas-0.22.0\n",
      "\u001b[91mYou are using pip version 10.0.1, however version 20.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "\u001b[0mCollecting scikit-learn==0.19.1\n",
      "  Downloading https://files.pythonhosted.org/packages/c4/b8/eb447f84e0012b0bce97d12d1bc6ea6882b4ed9eb7faaca00e8f627733fb/scikit_learn-0.19.1-cp27-cp27mu-manylinux1_x86_64.whl (12.2MB)\n",
      "Installing collected packages: scikit-learn\n",
      "Successfully installed scikit-learn-0.19.1\n",
      "\u001b[91mYou are using pip version 10.0.1, however version 20.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "\u001b[0mRequirement already satisfied: cloudpickle in /opt/conda/lib/python2.7/site-packages (1.3.0)\n",
      "\u001b[91mYou are using pip version 10.0.1, however version 20.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "\u001b[0mRemoving intermediate container b541d45bb67c\n",
      " ---> 1b574333b71b\n",
      "Successfully built 1b574333b71b\n",
      "Successfully tagged mlflow-docker-example:latest\n"
     ]
    }
   ],
   "source": [
    "!docker image build -t mlflow-docker-example:latest -f ../test/docker/Dockerfile ."
   ]
  },
  {
   "source": [
    "The mlflow project file should look like this:\n",
    "```\n",
    "name: docker-example\n",
    "\n",
    "docker_env:\n",
    "  image:  mlflow-docker-example:latest\n",
    "\n",
    "entry_points:\n",
    "  main:\n",
    "    parameters:\n",
    "      alpha: float\n",
    "      l1_ratio: {type: float, default: 0.1}\n",
    "    command: \"python train.py --alpha {alpha} --l1-ratio {l1_ratio}\"\n",
    "```\n",
    "Nodice instead of a `conda_env` property we provide `docker_env` and the image we just built above.\n",
    "\n",
    "Now, we just need to run the mlflow project. Mlflow will grab the info and create the container to run the experiment. Notice the `command` option, here we tell to run a python program and execute the `train.py` script which is part of the project files."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2020/10/15 10:34:47 INFO mlflow.projects.docker: === Building docker image docker-example ===\n",
      "2020/10/15 10:34:47 INFO mlflow.projects.utils: === Created directory /tmp/tmpt83_9vgp for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2020/10/15 10:34:47 INFO mlflow.projects.backend.local: === Running command 'docker run --rm -v /home/ohtar10/tests/mlflow/notebooks/mlruns:/mlflow/tmp/mlruns -v /home/ohtar10/tests/mlflow/notebooks/mlruns/0/6d47addf45db41efaf17bcafdb82ad4d/artifacts:/home/ohtar10/tests/mlflow/notebooks/mlruns/0/6d47addf45db41efaf17bcafdb82ad4d/artifacts -e MLFLOW_RUN_ID=6d47addf45db41efaf17bcafdb82ad4d -e MLFLOW_TRACKING_URI=file:///mlflow/tmp/mlruns -e MLFLOW_EXPERIMENT_ID=0 docker-example:latest python train.py --alpha 0.5 --l1-ratio 0.1' in run with ID '6d47addf45db41efaf17bcafdb82ad4d' === \n",
      "/opt/conda/lib/python2.7/site-packages/mlflow/__init__.py:55: DeprecationWarning: MLflow support for Python 2 is deprecated and will be dropped in a future release. At that point, existing Python 2 workflows that use MLflow will continue to work without modification, but Python 2 users will no longer get access to the latest MLflow features and bugfixes. We recommend that you upgrade to Python 3 - see https://docs.python.org/3/howto/pyporting.html for a migration guide.\n",
      "  \"for a migration guide.\", DeprecationWarning)\n",
      "Elasticnet model (alpha=0.500000, l1_ratio=0.100000):\n",
      "  RMSE: 0.794793101903653\n",
      "  MAE: 0.6189130834228139\n",
      "  R2: 0.18411668718221808\n",
      "2020/10/15 10:34:49 INFO mlflow.projects: === Run (ID '6d47addf45db41efaf17bcafdb82ad4d') succeeded ===\n"
     ]
    }
   ],
   "source": [
    "!mlflow run ../test/docker -P alpha=0.5"
   ]
  },
  {
   "source": [
    "If you pay attention, mlflow automatically creates the container with shared volumes to preserve the experiment results and it will automatically publish the results in the specified tracking uri."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Working with a remote tracking server\n",
    "All examples above work perfectly in local environments. However, it is normal to use a remote tracking server because there is where the final experiments will be stored and there is where we can have a model registry to keep track of all the experiments, versions, expose them as services etc.\n",
    "\n",
    "For this part of the demo I have prepared a docker-compose runtime environment with a postgres data base as a backend registry and a shared volume as model registry. Then we can run several experiments against this instance and we will be able to keep track of each experiment. We just need to ensure to specify the `MLFLOW_TRACKING_URI` environment variable to where the server is running. Then, all the experiments can run normally.\n",
    "\n",
    "In this particular case, one of the containers will run an mlflow server (not just a simple ui server) with the following command:\n",
    "```\n",
    "mlflow server --backend-store-uri postgresql://mlflow-store:123456@mlflow-store/mlflow-store --default-artifact-root /tmp/mlflow --host 0.0.0.0\n",
    "```\n",
    "Where:\n",
    "\n",
    "* `backend-store-uri` is the postgres data base uri.\n",
    "* `default-artifact-root` is the artifact store, i.e., where the models are actually stored, this can be an s3 bucket or some other external storage. It is recommended this to be visible from all the nodes that will interact wit the tracking server since there is where the local mlflow instance will publish the models.\n",
    "* `host` by default, mlflow server only listens from localhost, we need to specify the net adress we want the server to listen to.\n",
    "\n",
    "Once more, we can run experiments as we did above, but specifying the remote tracking server uri.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this before running the compose file to ensure permissions to a common volumne\n",
    "! mkdir -p /tmp/mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export MLFLOW_TRACKING_URI=http://localhost:5000/\n",
    "python mlflow_tracking.py"
   ]
  },
  {
   "source": [
    "We can now observe the results in the remote server, including the artifacts!\n",
    "\n",
    "It is a good practice to provide names to the experiments so that they can be organized in the tracking server under the same name, it is easier to track progress and compare metrics between runs of the same experiment name."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO: 'sklearn-en-wine' does not exist. Creating a new experiment\n",
      "Elasticnet model (alpha=0.350000, l1_ratio=0.100000):\n",
      "  RMSE: 0.7380094532393624\n",
      "  MAE: 0.5685087888806625\n",
      "  R2: 0.22828386798815148\n",
      "2020/10/16 06:41:08 INFO mlflow.projects.utils: === Created directory /tmp/tmpizzn2vw1 for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2020/10/16 06:41:08 INFO mlflow.projects.backend.local: === Running command 'source /home/ohtar10/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-6284a367a61b51ccdf445333a216776597fb4efc 1>&2 && python train.py 0.35 0.1' in run with ID '366cbbfbf4e74f2b9c0ec373fc7f322f' === \n",
      "Successfully registered model 'ElasticnetWineModel'.\n",
      "Created version '1' of model 'ElasticnetWineModel'.\n",
      "2020/10/16 06:41:11 INFO mlflow.projects: === Run (ID '366cbbfbf4e74f2b9c0ec373fc7f322f') succeeded ===\n",
      "CPU times: user 0 ns, sys: 6.26 ms, total: 6.26 ms\n",
      "Wall time: 6.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash\n",
    "export MLFLOW_TRACKING_URI=http://localhost:5000/\n",
    "mlflow run --experiment-name sklearn-en-wine ~/git/mlflow/examples/sklearn_elasticnet_wine/ -P alpha=0.35 -P l1_ratio=0.1"
   ]
  },
  {
   "source": [
    "We can run several runs for the same experiments to compare performance:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Elasticnet model (alpha=0.500000, l1_ratio=0.100000):\n",
      "  RMSE: 0.7460550348172179\n",
      "  MAE: 0.576381895873763\n",
      "  R2: 0.21136606570632266\n",
      "Elasticnet model (alpha=0.400000, l1_ratio=0.100000):\n",
      "  RMSE: 0.7410782793160982\n",
      "  MAE: 0.5712718681984226\n",
      "  R2: 0.22185255063708886\n",
      "Elasticnet model (alpha=0.500000, l1_ratio=0.200000):\n",
      "  RMSE: 0.7543919979968401\n",
      "  MAE: 0.5857669727382302\n",
      "  R2: 0.19364204365178084\n",
      "Elasticnet model (alpha=0.400000, l1_ratio=0.200000):\n",
      "  RMSE: 0.7468093030485083\n",
      "  MAE: 0.5777243300021722\n",
      "  R2: 0.20977062786327272\n",
      "Elasticnet model (alpha=0.350000, l1_ratio=0.200000):\n",
      "  RMSE: 0.7431910168050467\n",
      "  MAE: 0.5739937604254349\n",
      "  R2: 0.2174093904435277\n",
      "2020/10/16 06:41:41 INFO mlflow.projects.utils: === Created directory /tmp/tmpu36s0uc4 for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2020/10/16 06:41:41 INFO mlflow.projects.backend.local: === Running command 'source /home/ohtar10/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-6284a367a61b51ccdf445333a216776597fb4efc 1>&2 && python train.py 0.5 0.1' in run with ID '1eb6064977054c88b41e08d6cd612afb' === \n",
      "Registered model 'ElasticnetWineModel' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'ElasticnetWineModel'.\n",
      "2020/10/16 06:41:43 INFO mlflow.projects: === Run (ID '1eb6064977054c88b41e08d6cd612afb') succeeded ===\n",
      "2020/10/16 06:41:47 INFO mlflow.projects.utils: === Created directory /tmp/tmpmklyz63s for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2020/10/16 06:41:47 INFO mlflow.projects.backend.local: === Running command 'source /home/ohtar10/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-6284a367a61b51ccdf445333a216776597fb4efc 1>&2 && python train.py 0.4 0.1' in run with ID 'fb772e1991784faf83f0f13090ce04a6' === \n",
      "Registered model 'ElasticnetWineModel' already exists. Creating a new version of this model...\n",
      "Created version '3' of model 'ElasticnetWineModel'.\n",
      "2020/10/16 06:41:49 INFO mlflow.projects: === Run (ID 'fb772e1991784faf83f0f13090ce04a6') succeeded ===\n",
      "2020/10/16 06:41:53 INFO mlflow.projects.utils: === Created directory /tmp/tmpszr6tuz6 for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2020/10/16 06:41:53 INFO mlflow.projects.backend.local: === Running command 'source /home/ohtar10/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-6284a367a61b51ccdf445333a216776597fb4efc 1>&2 && python train.py 0.5 0.2' in run with ID '599efb0a63ef4be1bad3c04048d5808d' === \n",
      "Registered model 'ElasticnetWineModel' already exists. Creating a new version of this model...\n",
      "Created version '4' of model 'ElasticnetWineModel'.\n",
      "2020/10/16 06:41:55 INFO mlflow.projects: === Run (ID '599efb0a63ef4be1bad3c04048d5808d') succeeded ===\n",
      "2020/10/16 06:41:59 INFO mlflow.projects.utils: === Created directory /tmp/tmpks3e75mr for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2020/10/16 06:41:59 INFO mlflow.projects.backend.local: === Running command 'source /home/ohtar10/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-6284a367a61b51ccdf445333a216776597fb4efc 1>&2 && python train.py 0.4 0.2' in run with ID '7eb40d651e3d46f0b45fc018a31a4947' === \n",
      "Registered model 'ElasticnetWineModel' already exists. Creating a new version of this model...\n",
      "Created version '5' of model 'ElasticnetWineModel'.\n",
      "2020/10/16 06:42:01 INFO mlflow.projects: === Run (ID '7eb40d651e3d46f0b45fc018a31a4947') succeeded ===\n",
      "2020/10/16 06:42:04 INFO mlflow.projects.utils: === Created directory /tmp/tmpctx3nlet for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2020/10/16 06:42:04 INFO mlflow.projects.backend.local: === Running command 'source /home/ohtar10/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-6284a367a61b51ccdf445333a216776597fb4efc 1>&2 && python train.py 0.35 0.2' in run with ID '190518b1d2994a63adeaef87f52339e2' === \n",
      "Registered model 'ElasticnetWineModel' already exists. Creating a new version of this model...\n",
      "Created version '6' of model 'ElasticnetWineModel'.\n",
      "2020/10/16 06:42:07 INFO mlflow.projects: === Run (ID '190518b1d2994a63adeaef87f52339e2') succeeded ===\n",
      "CPU times: user 7.72 ms, sys: 1.63 ms, total: 9.35 ms\n",
      "Wall time: 29.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash\n",
    "export MLFLOW_TRACKING_URI=http://localhost:5000/\n",
    "mlflow run --experiment-name sklearn-en-wine ~/git/mlflow/examples/sklearn_elasticnet_wine/ -P alpha=0.5 -P l1_ratio=0.1\n",
    "mlflow run --experiment-name sklearn-en-wine ~/git/mlflow/examples/sklearn_elasticnet_wine/ -P alpha=0.4 -P l1_ratio=0.1\n",
    "mlflow run --experiment-name sklearn-en-wine ~/git/mlflow/examples/sklearn_elasticnet_wine/ -P alpha=0.5 -P l1_ratio=0.2\n",
    "mlflow run --experiment-name sklearn-en-wine ~/git/mlflow/examples/sklearn_elasticnet_wine/ -P alpha=0.4 -P l1_ratio=0.2\n",
    "mlflow run --experiment-name sklearn-en-wine ~/git/mlflow/examples/sklearn_elasticnet_wine/ -P alpha=0.35 -P l1_ratio=0.2"
   ]
  },
  {
   "source": [
    "### Serving models from the registry\n",
    "The above example not only runs an experiment but also registers a model in mlflow. We can then serve registered models to do AdHoc tests. In the above example we run the experiment 6 times, hence, we end up with 6 versions of `ElasticnetWineModel`. We simply do:\n",
    "\n",
    "```\n",
    "export MLFLOW_TRACKING_URI=http://localhost:5000/\n",
    "mlflow models serve -m \"models:/ElasticnetWineModel/6\" -p 1234\n",
    "```\n",
    "\n",
    "This will create the service instance at port 1234 using the version 6 of the model. We can execute a curl call then."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[4.950647762564361]"
     ]
    }
   ],
   "source": [
    "!curl -d '{\"columns\":[\"fixed acidity\", \"volatile acidity\", \"citric acid\", \"residual sugar\", \"chlorides\", \"free sulfur dioxide\", \"total sulfur dioxide\", \"density\", \"pH\", \"sulphates\", \"alcohol\"], \"data\":[[7, 0.27, 0.36, 20.7, 0.045, 45, 150, 1.001, 3, 0.45, 8.8]]}' -H 'Content-Type: application/json; format=pandas-split' -X POST http://localhost:1234/invocations"
   ]
  },
  {
   "source": [
    "## Pytorch with tensorboard\n",
    "This example "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO: 'pytorch-mnist' does not exist. Creating a new experiment\n",
      "Writing TensorBoard events locally to /tmp/tmpevkxoefe\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 4.150528\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 3.036672\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.609706\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.450013\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.467068\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.440793\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.259091\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 2.389473\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.199184\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 2.153472\n",
      "\n",
      "Test set: Average loss: 4.7327, Accuracy: 9695/10000 (97%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.234135\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 2.211236\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 2.179456\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 2.092092\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 2.220397\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 2.406422\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 2.238102\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 2.400642\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 2.115719\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 2.140153\n",
      "\n",
      "Test set: Average loss: 4.6956, Accuracy: 9763/10000 (98%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.145136\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 2.288123\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 2.176974\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 2.152493\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 2.177469\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 2.134097\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 2.229198\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 2.405380\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 2.204578\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 2.089817\n",
      "\n",
      "Test set: Average loss: 4.6816, Accuracy: 9821/10000 (98%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 2.227148\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 2.147449\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 2.098213\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 2.053894\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 2.246794\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 2.097247\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 2.082567\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 2.220534\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 2.132198\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 2.207970\n",
      "\n",
      "Test set: Average loss: 4.6736, Accuracy: 9831/10000 (98%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 2.100714\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 2.044970\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 2.212345\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 2.169218\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 2.063304\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 2.183371\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 1.994907\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 2.218353\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 2.135648\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 2.483434\n",
      "\n",
      "Test set: Average loss: 4.6662, Accuracy: 9849/10000 (98%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 2.140965\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 2.220959\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 2.220383\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 2.200722\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 2.284517\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 2.087092\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 2.078006\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 2.184506\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 2.021012\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 2.067739\n",
      "\n",
      "Test set: Average loss: 4.6652, Accuracy: 9846/10000 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 2.034074\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 2.110100\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 2.146649\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 2.045547\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 2.025051\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 2.081117\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 2.017577\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 2.107059\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 1.992569\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 2.015911\n",
      "\n",
      "Test set: Average loss: 4.6619, Accuracy: 9857/10000 (99%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 2.216469\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 2.021868\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 2.096153\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 1.982591\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 1.994942\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 2.000300\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 2.212058\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 2.067127\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 2.161144\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 2.142962\n",
      "\n",
      "Test set: Average loss: 4.6603, Accuracy: 9869/10000 (99%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 2.144725\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 2.117270\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 2.082598\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 2.028000\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 2.040964\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 2.065800\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 2.318753\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 2.090183\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 2.227262\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 2.104603\n",
      "\n",
      "Test set: Average loss: 4.6589, Accuracy: 9859/10000 (99%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 2.155252\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 2.105408\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 2.045826\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 2.060022\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 2.062715\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 2.109349\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 2.080275\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 2.064603\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 2.051770\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 2.089935\n",
      "\n",
      "Test set: Average loss: 4.6573, Accuracy: 9880/10000 (99%)\n",
      "\n",
      "Uploading TensorBoard events as a run artifact...\n",
      "\n",
      "Launch TensorBoard with:\n",
      "\n",
      "tensorboard --logdir=/tmp/mlflow/2/389c11d3da7c4ae0af2d23cc5ec61653/artifacts/events\n",
      "\n",
      "Logging the trained model as a run artifact...\n",
      "\n",
      "The model is logged at:\n",
      "/tmp/mlflow/2/389c11d3da7c4ae0af2d23cc5ec61653/artifacts/pytorch-model\n",
      "\n",
      "Sample predictions\n",
      "Sample 0 : Ground truth is \"0\", model prediction is \"0\"\n",
      "Sample 1 : Ground truth is \"8\", model prediction is \"8\"\n",
      "Sample 2 : Ground truth is \"7\", model prediction is \"7\"\n",
      "Sample 3 : Ground truth is \"8\", model prediction is \"8\"\n",
      "Sample 4 : Ground truth is \"0\", model prediction is \"0\"\n",
      "2020/10/16 06:49:36 INFO mlflow.projects.utils: === Created directory /tmp/tmpdl7i9kde for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2020/10/16 06:49:36 INFO mlflow.projects.backend.local: === Running command 'source /home/ohtar10/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419 1>&2 && python mnist_tensorboard_artifact.py \\\n",
      "  --batch-size 64 \\\n",
      "  --test-batch-size 1000 \\\n",
      "  --epochs 10 \\\n",
      "  --lr 0.05 \\\n",
      "  --momentum 0.5 \\\n",
      "  --enable-cuda True \\\n",
      "  --seed 5 \\\n",
      "  --log-interval 100\n",
      "' in run with ID '389c11d3da7c4ae0af2d23cc5ec61653' === \n",
      "/home/ohtar10/miniconda3/envs/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419/lib/python3.6/site-packages/torchvision/io/video.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "2020/10/16 06:51:19 INFO mlflow.projects: === Run (ID '389c11d3da7c4ae0af2d23cc5ec61653') succeeded ===\n",
      "CPU times: user 14 ms, sys: 1.78 ms, total: 15.8 ms\n",
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash\n",
    "export MLFLOW_TRACKING_URI=http://localhost:5000/\n",
    "mlflow run --experiment-name pytorch-mnist ~/git/mlflow/examples/pytorch/ -P lr=0.05 -P epochs=10 -P momentum=0.5"
   ]
  },
  {
   "source": [
    "Now let's run some other experiments to compare"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "16748\n",
      "Train Epoch: 22 [6400/60000 (11%)]\tLoss: 2.195884\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 2.091703\n",
      "Train Epoch: 22 [19200/60000 (32%)]\tLoss: 2.166260\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 2.019448\n",
      "Train Epoch: 22 [32000/60000 (53%)]\tLoss: 2.212389\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 2.045449\n",
      "Train Epoch: 22 [44800/60000 (75%)]\tLoss: 2.018580\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 2.066689\n",
      "Train Epoch: 22 [57600/60000 (96%)]\tLoss: 2.108426\n",
      "\n",
      "Test set: Average loss: 4.6723, Accuracy: 9835/10000 (98%)\n",
      "\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 2.229296\n",
      "Train Epoch: 23 [6400/60000 (11%)]\tLoss: 2.033583\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 2.158364\n",
      "Train Epoch: 23 [19200/60000 (32%)]\tLoss: 2.054777\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 2.070736\n",
      "Train Epoch: 23 [32000/60000 (53%)]\tLoss: 2.125326\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 1.999015\n",
      "Train Epoch: 23 [44800/60000 (75%)]\tLoss: 2.036064\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 2.228644\n",
      "Train Epoch: 23 [57600/60000 (96%)]\tLoss: 2.141186\n",
      "\n",
      "Test set: Average loss: 4.6709, Accuracy: 9837/10000 (98%)\n",
      "\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 2.202701\n",
      "Train Epoch: 24 [6400/60000 (11%)]\tLoss: 2.037069\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 2.087379\n",
      "Train Epoch: 24 [19200/60000 (32%)]\tLoss: 2.118052\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 2.310991\n",
      "Train Epoch: 24 [32000/60000 (53%)]\tLoss: 2.155372\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 2.099230\n",
      "Train Epoch: 24 [44800/60000 (75%)]\tLoss: 2.008341\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 2.125401\n",
      "Train Epoch: 24 [57600/60000 (96%)]\tLoss: 2.121268\n",
      "\n",
      "Test set: Average loss: 4.6700, Accuracy: 9841/10000 (98%)\n",
      "\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 2.247315\n",
      "Train Epoch: 25 [6400/60000 (11%)]\tLoss: 2.234205\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 2.378944\n",
      "Train Epoch: 25 [19200/60000 (32%)]\tLoss: 2.131991\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 2.019537\n",
      "Train Epoch: 25 [32000/60000 (53%)]\tLoss: 2.106926\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 2.241848\n",
      "Train Epoch: 25 [44800/60000 (75%)]\tLoss: 2.091963\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 2.171436\n",
      "Train Epoch: 25 [57600/60000 (96%)]\tLoss: 2.193812\n",
      "\n",
      "Test set: Average loss: 4.6691, Accuracy: 9842/10000 (98%)\n",
      "\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 2.028548\n",
      "Train Epoch: 26 [6400/60000 (11%)]\tLoss: 2.231704\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 2.178877\n",
      "Train Epoch: 26 [19200/60000 (32%)]\tLoss: 2.304847\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 2.004170\n",
      "Train Epoch: 26 [32000/60000 (53%)]\tLoss: 2.043682\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 2.242542\n",
      "Train Epoch: 26 [44800/60000 (75%)]\tLoss: 2.107031\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 2.106581\n",
      "Train Epoch: 26 [57600/60000 (96%)]\tLoss: 2.061150\n",
      "\n",
      "Test set: Average loss: 4.6663, Accuracy: 9832/10000 (98%)\n",
      "\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 2.093587\n",
      "Train Epoch: 27 [6400/60000 (11%)]\tLoss: 2.116109\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 2.070312\n",
      "Train Epoch: 27 [19200/60000 (32%)]\tLoss: 2.117893\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 2.187182\n",
      "Train Epoch: 27 [32000/60000 (53%)]\tLoss: 2.079564\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 2.319236\n",
      "Train Epoch: 27 [44800/60000 (75%)]\tLoss: 1.966001\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 2.174507\n",
      "Train Epoch: 27 [57600/60000 (96%)]\tLoss: 2.065502\n",
      "\n",
      "Test set: Average loss: 4.6665, Accuracy: 9844/10000 (98%)\n",
      "\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 2.076344\n",
      "Train Epoch: 28 [6400/60000 (11%)]\tLoss: 2.063082\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 2.200976\n",
      "Train Epoch: 28 [19200/60000 (32%)]\tLoss: 2.242862\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 2.099033\n",
      "Train Epoch: 28 [32000/60000 (53%)]\tLoss: 2.154114\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 2.087269\n",
      "Train Epoch: 28 [44800/60000 (75%)]\tLoss: 2.105985\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 2.137125\n",
      "Train Epoch: 28 [57600/60000 (96%)]\tLoss: 2.041747\n",
      "\n",
      "Test set: Average loss: 4.6653, Accuracy: 9849/10000 (98%)\n",
      "\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 2.282751\n",
      "Train Epoch: 29 [6400/60000 (11%)]\tLoss: 2.283026\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 2.063750\n",
      "Train Epoch: 29 [19200/60000 (32%)]\tLoss: 2.023429\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 2.200556\n",
      "Train Epoch: 29 [32000/60000 (53%)]\tLoss: 2.089996\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 2.043025\n",
      "Train Epoch: 29 [44800/60000 (75%)]\tLoss: 2.096231\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 2.075133\n",
      "Train Epoch: 29 [57600/60000 (96%)]\tLoss: 2.056022\n",
      "\n",
      "Test set: Average loss: 4.6637, Accuracy: 9854/10000 (99%)\n",
      "\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 2.180581\n",
      "Train Epoch: 30 [6400/60000 (11%)]\tLoss: 2.060115\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 2.177342\n",
      "Train Epoch: 30 [19200/60000 (32%)]\tLoss: 2.084698\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 2.077070\n",
      "Train Epoch: 30 [32000/60000 (53%)]\tLoss: 2.070929\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 2.133357\n",
      "Train Epoch: 30 [44800/60000 (75%)]\tLoss: 2.180728\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 1.986391\n",
      "Train Epoch: 30 [57600/60000 (96%)]\tLoss: 2.152080\n",
      "\n",
      "Test set: Average loss: 4.6645, Accuracy: 9846/10000 (98%)\n",
      "\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 2.032874\n",
      "Train Epoch: 31 [6400/60000 (11%)]\tLoss: 2.043099\n",
      "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 2.180310\n",
      "Train Epoch: 31 [19200/60000 (32%)]\tLoss: 2.233696\n",
      "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 2.216369\n",
      "Train Epoch: 31 [32000/60000 (53%)]\tLoss: 2.027436\n",
      "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 2.086900\n",
      "Train Epoch: 31 [44800/60000 (75%)]\tLoss: 2.027464\n",
      "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 2.116299\n",
      "Train Epoch: 31 [57600/60000 (96%)]\tLoss: 2.016521\n",
      "\n",
      "Test set: Average loss: 4.6654, Accuracy: 9860/10000 (99%)\n",
      "\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 2.106827\n",
      "Train Epoch: 32 [6400/60000 (11%)]\tLoss: 2.151294\n",
      "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 2.096859\n",
      "Train Epoch: 32 [19200/60000 (32%)]\tLoss: 2.029453\n",
      "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 2.062710\n",
      "Train Epoch: 32 [32000/60000 (53%)]\tLoss: 2.065102\n",
      "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 2.106210\n",
      "Train Epoch: 32 [44800/60000 (75%)]\tLoss: 2.059615\n",
      "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 2.057231\n",
      "Train Epoch: 32 [57600/60000 (96%)]\tLoss: 2.206180\n",
      "\n",
      "Test set: Average loss: 4.6635, Accuracy: 9858/10000 (99%)\n",
      "\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 2.250779\n",
      "Train Epoch: 33 [6400/60000 (11%)]\tLoss: 2.105307\n",
      "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 2.019737\n",
      "Train Epoch: 33 [19200/60000 (32%)]\tLoss: 2.025459\n",
      "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 2.111061\n",
      "Train Epoch: 33 [32000/60000 (53%)]\tLoss: 1.975406\n",
      "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 2.066709\n",
      "Train Epoch: 33 [44800/60000 (75%)]\tLoss: 2.106528\n",
      "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 2.095015\n",
      "Train Epoch: 33 [57600/60000 (96%)]\tLoss: 2.060534\n",
      "\n",
      "Test set: Average loss: 4.6623, Accuracy: 9865/10000 (99%)\n",
      "\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 2.098801\n",
      "Train Epoch: 34 [6400/60000 (11%)]\tLoss: 2.097351\n",
      "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 2.124317\n",
      "Train Epoch: 34 [19200/60000 (32%)]\tLoss: 2.103849\n",
      "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 2.099045\n",
      "Train Epoch: 34 [32000/60000 (53%)]\tLoss: 2.111381\n",
      "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 2.128922\n",
      "Train Epoch: 34 [44800/60000 (75%)]\tLoss: 2.145932\n",
      "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 2.019706\n",
      "Train Epoch: 34 [57600/60000 (96%)]\tLoss: 2.077237\n",
      "\n",
      "Test set: Average loss: 4.6617, Accuracy: 9858/10000 (99%)\n",
      "\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 2.094332\n",
      "Train Epoch: 35 [6400/60000 (11%)]\tLoss: 2.263954\n",
      "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 2.179660\n",
      "Train Epoch: 35 [19200/60000 (32%)]\tLoss: 2.002134\n",
      "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 2.112061\n",
      "Train Epoch: 35 [32000/60000 (53%)]\tLoss: 2.096216\n",
      "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 2.217815\n",
      "Train Epoch: 35 [44800/60000 (75%)]\tLoss: 1.976460\n",
      "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 2.032494\n",
      "Train Epoch: 35 [57600/60000 (96%)]\tLoss: 2.047023\n",
      "\n",
      "Test set: Average loss: 4.6624, Accuracy: 9855/10000 (99%)\n",
      "\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 2.324040\n",
      "Train Epoch: 36 [6400/60000 (11%)]\tLoss: 2.009561\n",
      "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 2.021806\n",
      "Train Epoch: 36 [19200/60000 (32%)]\tLoss: 2.015919\n",
      "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 2.103539\n",
      "Train Epoch: 36 [32000/60000 (53%)]\tLoss: 2.334356\n",
      "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 2.124480\n",
      "Train Epoch: 36 [44800/60000 (75%)]\tLoss: 2.193257\n",
      "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 2.013916\n",
      "Train Epoch: 36 [57600/60000 (96%)]\tLoss: 2.091427\n",
      "\n",
      "Test set: Average loss: 4.6616, Accuracy: 9855/10000 (99%)\n",
      "\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 2.027274\n",
      "Train Epoch: 37 [6400/60000 (11%)]\tLoss: 2.084142\n",
      "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 2.112842\n",
      "Train Epoch: 37 [19200/60000 (32%)]\tLoss: 1.986138\n",
      "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 2.018415\n",
      "Train Epoch: 37 [32000/60000 (53%)]\tLoss: 2.016812\n",
      "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 2.060560\n",
      "Train Epoch: 37 [44800/60000 (75%)]\tLoss: 2.078292\n",
      "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 2.194769\n",
      "Train Epoch: 37 [57600/60000 (96%)]\tLoss: 2.176001\n",
      "\n",
      "Test set: Average loss: 4.6625, Accuracy: 9864/10000 (99%)\n",
      "\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 2.262904\n",
      "Train Epoch: 38 [6400/60000 (11%)]\tLoss: 2.023288\n",
      "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 2.032532\n",
      "Train Epoch: 38 [19200/60000 (32%)]\tLoss: 2.069269\n",
      "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 2.067112\n",
      "Train Epoch: 38 [32000/60000 (53%)]\tLoss: 2.119690\n",
      "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 2.096185\n",
      "Train Epoch: 38 [44800/60000 (75%)]\tLoss: 1.952009\n",
      "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 2.227376\n",
      "Train Epoch: 38 [57600/60000 (96%)]\tLoss: 1.938222\n",
      "\n",
      "Test set: Average loss: 4.6580, Accuracy: 9868/10000 (99%)\n",
      "\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 2.012949\n",
      "Train Epoch: 39 [6400/60000 (11%)]\tLoss: 2.019449\n",
      "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 2.023294\n",
      "Train Epoch: 39 [19200/60000 (32%)]\tLoss: 1.995192\n",
      "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 2.181937\n",
      "Train Epoch: 39 [32000/60000 (53%)]\tLoss: 2.139605\n",
      "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 2.052474\n",
      "Train Epoch: 39 [44800/60000 (75%)]\tLoss: 2.077269\n",
      "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 2.304280\n",
      "Train Epoch: 39 [57600/60000 (96%)]\tLoss: 2.064499\n",
      "\n",
      "Test set: Average loss: 4.6597, Accuracy: 9876/10000 (99%)\n",
      "\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 2.147937\n",
      "Train Epoch: 40 [6400/60000 (11%)]\tLoss: 2.064288\n",
      "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 2.205335\n",
      "Train Epoch: 40 [19200/60000 (32%)]\tLoss: 2.117422\n",
      "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 2.131306\n",
      "Train Epoch: 40 [32000/60000 (53%)]\tLoss: 2.134809\n",
      "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 2.002421\n",
      "Train Epoch: 40 [44800/60000 (75%)]\tLoss: 2.070840\n",
      "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 2.101453\n",
      "Train Epoch: 40 [57600/60000 (96%)]\tLoss: 2.002855\n",
      "\n",
      "Test set: Average loss: 4.6572, Accuracy: 9861/10000 (99%)\n",
      "\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 2.121245\n",
      "Train Epoch: 41 [6400/60000 (11%)]\tLoss: 2.079234\n",
      "Train Epoch: 41 [12800/60000 (21%)]\tLoss: 2.237423\n",
      "Train Epoch: 41 [19200/60000 (32%)]\tLoss: 1.993103\n",
      "Train Epoch: 41 [25600/60000 (43%)]\tLoss: 2.705883\n",
      "Train Epoch: 41 [32000/60000 (53%)]\tLoss: 2.052001\n",
      "Train Epoch: 41 [38400/60000 (64%)]\tLoss: 2.077677\n",
      "Train Epoch: 41 [44800/60000 (75%)]\tLoss: 1.965425\n",
      "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 2.056006\n",
      "Train Epoch: 41 [57600/60000 (96%)]\tLoss: 2.009849\n",
      "\n",
      "Test set: Average loss: 4.6580, Accuracy: 9869/10000 (99%)\n",
      "\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 1.988290\n",
      "Train Epoch: 42 [6400/60000 (11%)]\tLoss: 2.047707\n",
      "Train Epoch: 42 [12800/60000 (21%)]\tLoss: 2.042881\n",
      "Train Epoch: 42 [19200/60000 (32%)]\tLoss: 2.099444\n",
      "Train Epoch: 42 [25600/60000 (43%)]\tLoss: 2.247785\n",
      "Train Epoch: 42 [32000/60000 (53%)]\tLoss: 2.149507\n",
      "Train Epoch: 42 [38400/60000 (64%)]\tLoss: 2.090450\n",
      "Train Epoch: 42 [44800/60000 (75%)]\tLoss: 2.009638\n",
      "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 2.074119\n",
      "Train Epoch: 42 [57600/60000 (96%)]\tLoss: 2.025442\n",
      "\n",
      "Test set: Average loss: 4.6608, Accuracy: 9864/10000 (99%)\n",
      "\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 1.990599\n",
      "Train Epoch: 43 [6400/60000 (11%)]\tLoss: 2.154304\n",
      "Train Epoch: 43 [12800/60000 (21%)]\tLoss: 2.065404\n",
      "Train Epoch: 43 [19200/60000 (32%)]\tLoss: 2.099399\n",
      "Train Epoch: 43 [25600/60000 (43%)]\tLoss: 2.006883\n",
      "Train Epoch: 43 [32000/60000 (53%)]\tLoss: 2.274453\n",
      "Train Epoch: 43 [38400/60000 (64%)]\tLoss: 2.230206\n",
      "Train Epoch: 43 [44800/60000 (75%)]\tLoss: 2.145746\n",
      "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 2.047088\n",
      "Train Epoch: 43 [57600/60000 (96%)]\tLoss: 2.053350\n",
      "\n",
      "Test set: Average loss: 4.6579, Accuracy: 9869/10000 (99%)\n",
      "\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 2.023051\n",
      "Train Epoch: 44 [6400/60000 (11%)]\tLoss: 2.026546\n",
      "Train Epoch: 44 [12800/60000 (21%)]\tLoss: 1.980302\n",
      "Train Epoch: 44 [19200/60000 (32%)]\tLoss: 2.072607\n",
      "Train Epoch: 44 [25600/60000 (43%)]\tLoss: 2.203123\n",
      "Train Epoch: 44 [32000/60000 (53%)]\tLoss: 2.092225\n",
      "Train Epoch: 44 [38400/60000 (64%)]\tLoss: 1.969308\n",
      "Train Epoch: 44 [44800/60000 (75%)]\tLoss: 1.958282\n",
      "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 2.097814\n",
      "Train Epoch: 44 [57600/60000 (96%)]\tLoss: 2.065714\n",
      "\n",
      "Test set: Average loss: 4.6571, Accuracy: 9873/10000 (99%)\n",
      "\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 2.037733\n",
      "Train Epoch: 45 [6400/60000 (11%)]\tLoss: 2.025395\n",
      "Train Epoch: 45 [12800/60000 (21%)]\tLoss: 2.107319\n",
      "Train Epoch: 45 [19200/60000 (32%)]\tLoss: 1.974695\n",
      "Train Epoch: 45 [25600/60000 (43%)]\tLoss: 2.037608\n",
      "Train Epoch: 45 [32000/60000 (53%)]\tLoss: 2.050337\n",
      "Train Epoch: 45 [38400/60000 (64%)]\tLoss: 1.958656\n",
      "Train Epoch: 45 [44800/60000 (75%)]\tLoss: 2.180213\n",
      "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 2.056049\n",
      "Train Epoch: 45 [57600/60000 (96%)]\tLoss: 2.038548\n",
      "\n",
      "Test set: Average loss: 4.6579, Accuracy: 9870/10000 (99%)\n",
      "\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 1.964452\n",
      "Train Epoch: 46 [6400/60000 (11%)]\tLoss: 2.167126\n",
      "Train Epoch: 46 [12800/60000 (21%)]\tLoss: 2.031176\n",
      "Train Epoch: 46 [19200/60000 (32%)]\tLoss: 2.082838\n",
      "Train Epoch: 46 [25600/60000 (43%)]\tLoss: 2.035084\n",
      "Train Epoch: 46 [32000/60000 (53%)]\tLoss: 2.108995\n",
      "Train Epoch: 46 [38400/60000 (64%)]\tLoss: 2.100848\n",
      "Train Epoch: 46 [44800/60000 (75%)]\tLoss: 2.013692\n",
      "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 2.011591\n",
      "Train Epoch: 46 [57600/60000 (96%)]\tLoss: 2.100654\n",
      "\n",
      "Test set: Average loss: 4.6583, Accuracy: 9877/10000 (99%)\n",
      "\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 2.071181\n",
      "Train Epoch: 47 [6400/60000 (11%)]\tLoss: 2.124856\n",
      "Train Epoch: 47 [12800/60000 (21%)]\tLoss: 2.023238\n",
      "Train Epoch: 47 [19200/60000 (32%)]\tLoss: 2.064977\n",
      "Train Epoch: 47 [25600/60000 (43%)]\tLoss: 2.205106\n",
      "Train Epoch: 47 [32000/60000 (53%)]\tLoss: 2.107256\n",
      "Train Epoch: 47 [38400/60000 (64%)]\tLoss: 2.064999\n",
      "Train Epoch: 47 [44800/60000 (75%)]\tLoss: 2.036960\n",
      "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 2.028953\n",
      "Train Epoch: 47 [57600/60000 (96%)]\tLoss: 2.144808\n",
      "\n",
      "Test set: Average loss: 4.6579, Accuracy: 9874/10000 (99%)\n",
      "\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 2.122563\n",
      "Train Epoch: 48 [6400/60000 (11%)]\tLoss: 2.070669\n",
      "Train Epoch: 48 [12800/60000 (21%)]\tLoss: 2.129592\n",
      "Train Epoch: 48 [19200/60000 (32%)]\tLoss: 1.965931\n",
      "Train Epoch: 48 [25600/60000 (43%)]\tLoss: 2.085959\n",
      "Train Epoch: 48 [32000/60000 (53%)]\tLoss: 2.020982\n",
      "Train Epoch: 48 [38400/60000 (64%)]\tLoss: 2.053939\n",
      "Train Epoch: 48 [44800/60000 (75%)]\tLoss: 2.145029\n",
      "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 1.983607\n",
      "Train Epoch: 48 [57600/60000 (96%)]\tLoss: 2.115343\n",
      "\n",
      "Test set: Average loss: 4.6563, Accuracy: 9872/10000 (99%)\n",
      "\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLoss: 1.977888\n",
      "Train Epoch: 49 [6400/60000 (11%)]\tLoss: 2.052279\n",
      "Train Epoch: 49 [12800/60000 (21%)]\tLoss: 1.996144\n",
      "Train Epoch: 49 [19200/60000 (32%)]\tLoss: 2.021567\n",
      "Train Epoch: 49 [25600/60000 (43%)]\tLoss: 2.087155\n",
      "Train Epoch: 49 [32000/60000 (53%)]\tLoss: 2.023529\n",
      "Train Epoch: 49 [38400/60000 (64%)]\tLoss: 2.011133\n",
      "Train Epoch: 49 [44800/60000 (75%)]\tLoss: 1.953588\n",
      "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 2.166240\n",
      "Train Epoch: 49 [57600/60000 (96%)]\tLoss: 2.137295\n",
      "\n",
      "Test set: Average loss: 4.6558, Accuracy: 9873/10000 (99%)\n",
      "\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLoss: 2.215384\n",
      "Train Epoch: 50 [6400/60000 (11%)]\tLoss: 2.103723\n",
      "Train Epoch: 50 [12800/60000 (21%)]\tLoss: 2.094976\n",
      "Train Epoch: 50 [19200/60000 (32%)]\tLoss: 1.977146\n",
      "Train Epoch: 50 [25600/60000 (43%)]\tLoss: 2.094529\n",
      "Train Epoch: 50 [32000/60000 (53%)]\tLoss: 2.015737\n",
      "Train Epoch: 50 [38400/60000 (64%)]\tLoss: 2.139136\n",
      "Train Epoch: 50 [44800/60000 (75%)]\tLoss: 2.019966\n",
      "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 2.141513\n",
      "Train Epoch: 50 [57600/60000 (96%)]\tLoss: 2.036479\n",
      "\n",
      "Test set: Average loss: 4.6559, Accuracy: 9888/10000 (99%)\n",
      "\n",
      "Uploading TensorBoard events as a run artifact...\n",
      "\n",
      "Launch TensorBoard with:\n",
      "\n",
      "tensorboard --logdir=/tmp/mlflow/2/239e7bc80fe24a37a448cb863ea36d5a/artifacts/events\n",
      "\n",
      "Logging the trained model as a run artifact...\n",
      "\n",
      "The model is logged at:\n",
      "/tmp/mlflow/2/239e7bc80fe24a37a448cb863ea36d5a/artifacts/pytorch-model\n",
      "\n",
      "Sample predictions\n",
      "Sample 0 : Ground truth is \"0\", model prediction is \"0\"\n",
      "Sample 1 : Ground truth is \"3\", model prediction is \"3\"\n",
      "Sample 2 : Ground truth is \"8\", model prediction is \"8\"\n",
      "Sample 3 : Ground truth is \"1\", model prediction is \"1\"\n",
      "Sample 4 : Ground truth is \"8\", model prediction is \"8\"\n",
      "2020/10/16 06:52:26 INFO mlflow.projects.utils: === Created directory /tmp/tmpgri826xg for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2020/10/16 06:52:26 INFO mlflow.projects.backend.local: === Running command 'source /home/ohtar10/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419 1>&2 && python mnist_tensorboard_artifact.py \\\n",
      "  --batch-size 64 \\\n",
      "  --test-batch-size 1000 \\\n",
      "  --epochs 20 \\\n",
      "  --lr 0.01 \\\n",
      "  --momentum 0.5 \\\n",
      "  --enable-cuda True \\\n",
      "  --seed 5 \\\n",
      "  --log-interval 100\n",
      "' in run with ID '427f681bbd5945409db8b0e5519e310f' === \n",
      "/home/ohtar10/miniconda3/envs/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419/lib/python3.6/site-packages/torchvision/io/video.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "2020/10/16 06:55:48 INFO mlflow.projects: === Run (ID '427f681bbd5945409db8b0e5519e310f') succeeded ===\n",
      "2020/10/16 06:55:52 INFO mlflow.projects.utils: === Created directory /tmp/tmpqm2qo8v3 for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2020/10/16 06:55:52 INFO mlflow.projects.backend.local: === Running command 'source /home/ohtar10/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419 1>&2 && python mnist_tensorboard_artifact.py \\\n",
      "  --batch-size 64 \\\n",
      "  --test-batch-size 1000 \\\n",
      "  --epochs 20 \\\n",
      "  --lr 0.01 \\\n",
      "  --momentum 0.9 \\\n",
      "  --enable-cuda True \\\n",
      "  --seed 5 \\\n",
      "  --log-interval 100\n",
      "' in run with ID '0a1fcf8d142341ce9cdc84ab2309d697' === \n",
      "/home/ohtar10/miniconda3/envs/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419/lib/python3.6/site-packages/torchvision/io/video.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "2020/10/16 06:59:10 INFO mlflow.projects: === Run (ID '0a1fcf8d142341ce9cdc84ab2309d697') succeeded ===\n",
      "2020/10/16 06:59:14 INFO mlflow.projects.utils: === Created directory /tmp/tmpqpb8noqx for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2020/10/16 06:59:14 INFO mlflow.projects.backend.local: === Running command 'source /home/ohtar10/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419 1>&2 && python mnist_tensorboard_artifact.py \\\n",
      "  --batch-size 64 \\\n",
      "  --test-batch-size 1000 \\\n",
      "  --epochs 50 \\\n",
      "  --lr 0.001 \\\n",
      "  --momentum 0.9 \\\n",
      "  --enable-cuda True \\\n",
      "  --seed 5 \\\n",
      "  --log-interval 100\n",
      "' in run with ID '239e7bc80fe24a37a448cb863ea36d5a' === \n",
      "/home/ohtar10/miniconda3/envs/mlflow-3c24da0bdd94369e854abcee14bf75d1ad29c419/lib/python3.6/site-packages/torchvision/io/video.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "2020/10/16 07:07:40 INFO mlflow.projects: === Run (ID '239e7bc80fe24a37a448cb863ea36d5a') succeeded ===\n",
      "CPU times: user 56.9 ms, sys: 32.7 ms, total: 89.6 ms\n",
      "Wall time: 15min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash\n",
    "export MLFLOW_TRACKING_URI=http://localhost:5000/\n",
    "mlflow run --experiment-name pytorch-mnist ~/git/mlflow/examples/pytorch/ -P lr=0.01 -P epochs=20 -P momentum=0.5\n",
    "mlflow run --experiment-name pytorch-mnist ~/git/mlflow/examples/pytorch/ -P lr=0.01 -P epochs=20 -P momentum=0.9\n",
    "mlflow run --experiment-name pytorch-mnist ~/git/mlflow/examples/pytorch/ -P lr=0.001 -P epochs=50 -P momentum=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}